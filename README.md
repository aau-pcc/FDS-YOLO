# Multi-objective Bud Detection and Counting Model for Real Tea Plantation Environments<br>真实茶园环境中的多目标茶芽检测和计数模型.
## Introduction<br>
### Dataset:<br>
#### TeaBudVis（Xiaolanhua）<br>
TeaBudVis tea bud dataset photographed in early April 2024, tea buds are dense and shaded, labelled with only one tea category. Total 3070 images.<br>
The image is shown below:<br>
<div align="center">
  <img src="https://github.com/aau-pcc/FDS-YOLO/blob/main/TeaBudVis/Images/2024_04_07_10_47_IMG_3490.jpg" width="50%">
</div><br>

#### DiverseBudSet（Huangjinya、Longjinchangye、Zhongcha111）<br>
Collected in early, mid and late March 2025, respectively. In early March, the number of single bracts and single buds in the images was higher and the targets were smaller, more attached to the branch tips or obscured by the leaves, which was not easy to identify; in mid-March, the images were taken in rainy days with insufficient light, and the background was blurred under the shade of rainwater, which affected the details of the characteristics of the tea buds; in late March, compared with the two previous periods, the tea buds were growing rapidly, and the growth of the one-leaf shoots and one-leaf shoots was more intensive and there was significant The background is blurred by water, which affects the details of the tea buds' features.<br>
##### HuangjinyaSet<br>
Late-March pictures are shown below:<br>
<div align="center">
  <img src="https://github.com/aau-pcc/FDS-YOLO/blob/main/DiverseBudSet/HuangjinyaSet/late/images/2025_03_28_11_06_IMG_2713_001.jpg" width="50%">
</div><br>

##### LongJingSet<br>
Late-March pictures are shown below:<br>
<div align="center">
  <img src="https://github.com/aau-pcc/FDS-YOLO/blob/main/DiverseBudSet/LongJingSet/late/images/288.jpg" width="50%">
</div><br>

##### ZhongchaSet<br>
Late-March pictures are shown below:<br>
<div align="center">
  <img src="https://github.com/aau-pcc/FDS-YOLO/blob/main/DiverseBudSet/ZhongchaSet/late/images/2025_03_28_10_34_IMG_2322_003.jpg" width="50%">
</div><br>

### clarification<br>
Tea bud detection and counting in complex plantations face challenges due to shape/size variations, occlusion/overlap from dense growth and color similarity, and image diversity from varying camera distances. Current methods, focused on small-scale or specific conditions, often fail in real environments. Moreover, current video-based counting methods struggle with missed or false detections in consecutive frames and counting errors due to reliance on single-line counting techniques.<br>
To address these challenges, this study proposed a multi-objective tea bud detection and counting network model tailored for complex tea garden environments. The accuracy and generalization ability of tea bud detection and tracking were significantly improved by introducing advanced network architectures and optimization strategies, along with the development of a novel double-parallel line-based counting method. Meanwhile, by introducing the dynamic proportion of different types of tea buds at different times, the dynamic growth trend of tea buds can be observed more clearly.<br>
(1) We have created a total of two tea bud datasets, the largest of which is TeaBudVis - a comprehensive dataset containing 3070 in-field tea bud images with 50,997 high-quality bounding box annotations, specifically designed to address multi-scale detection challenges in authentic cultivation environments. In addition, we constructed the DiverseBudSet dataset, which contains three different types of tea buds photographed in three different time periods: Huangjingya, Longjingchangye, and Zhongcha. We labelled 6726 images with the aim of validating the generalisability of the model for different categories of tea bud detection in different scenarios. A total of 9796 images of tea buds were labelled, providing sufficient data for the experiments.<br>
(2) A feature discrimination system (FDS) that integrated Dual-Dynamic Token Learner (D-Mixer) and Squeeze-and-Excitation Network (SeNet) was designed. The dynamic feature aggregation weights generated by the FDS accounted for both global and local information, enhancing the extraction capability of the morphological features of tea buds and enabling a more comprehensive feature representation.<br>
(3) The proposed method was based on parallel line intersection counting in videos, which tracked and counted tea buds by analyzing their motion trajectories across consecutive video frames. This method effectively addressed counting errors caused by missed detections and false positives, improving the accuracy and reliability of the counting process.<br>
(4) Based on the statistical results of various tea bud quantities in videos from different time periods, a dynamic proportion was innovatively constructed, which can clearly quantify the growth trend of tea buds and provide assistance for future tea garden management decisions.<br>

##### Some experimental results of image detection<br>
Detection results on TeaBudVis：<br>
<div align="center">
  <img src="https://github.com/aau-pcc/FDS-YOLO/blob/main/pictures/1.png" width="50%">
</div><br>

##### Results of tea counts<br>
Regression analysis results of PLBC counting versus manual counting：<br>
<div align="center">
  <img src="https://github.com/aau-pcc/FDS-YOLO/blob/main/pictures/2.png" width="50%">
</div><br>

### :blush:Here we have only presented some sample images from the dataset. If you need them, please contact us to obtain more.<br>

